---
title: "Debiasing Representations by Removing Unwanted Variation Due to Protected Attributes"
collection: publications
permalink: /publication/debiasing
excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2018-07-15
venue: 'Fairness, Accountability, and Transparency in Machine Learning workshop at ICML'
paperurl: 'https://arxiv.org/pdf/1807.00461.pdf'
citation: 'Amanda Bower, Laura Niss, Yuekai Sun, and Alex Vargo. (2018). &quot;Debiasing Representations by Removing Unwanted Variation Due to Protected Attributes.&quot; <i>Fairness, Accountability, and Transparency in Machine Learning workshop at ICML</i>.'
---
<b>Abstract</b>: We propose a regression-based approach to removing implicit biases in representations. On tasks where the protected attribute is observed, the method is statistically more efficient than known approaches. Further, we show that this approach leads to debiased representations that satisfy a first order approximation of conditional parity. Finally, we demonstrate the efficacy of the proposed approach by reducing racial bias in recidivism risk scores.

<b>Authors</b>: Amanda Bower, Laura Niss, Yuekai Sun, and Alex Vargo. <i>Equal contribution.<i>

[Download paper here](https://arxiv.org/pdf/1807.00461.pdf)

[Github repo here](https://github.com/Amandarg/debias)
