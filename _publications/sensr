---
title: "Training individually fair ML models with sensitive subspace robustness"
collection: publications
permalink: /publication/sensr
excerpt: 'Algorithm for training individually fair classifier using adversarial robustness'
date: 2019-09-25
venue: 'International Conference for Learning Representations (ICLR)'
paperurl: 'https://openreview.net/forum?id=B1gdkxHFDH'
citation: ''
---
<b>Abstract</b>: We consider training machine learning models that are fair in the sense that their performance is invariant under certain sensitive perturbations to the inputs. For example, the performance of a resume screening system should be invariant under changes to the gender and/or ethnicity of the applicant. We formalize this notion of algorithmic fairness as a variant of individual fairness and develop a distributionally robust optimization approach to enforce it during training. We also demonstrate the effectiveness of the approach on two ML tasks that are susceptible to gender and racial biases. 
<b>Authors</b>: [Mikhail Yurochkin](https://moonfolk.github.io), Amanda Bower, [Yuekai Sun](https://yuekai.github.io). 

[Download paper here](https://openreview.net/forum?id=B1gdkxHFDH)

[Github repo here](https://github.com/IBM/sensitive-subspace-robustness)
